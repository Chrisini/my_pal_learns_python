{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATIONS_DIR = \"./locs/\"\n",
    "DATA_DIR = \"../../datasets/modis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geojson_context_figure(files: list[str]):\n",
    "    ## plot the geojson regions over a world map for checking\n",
    "    world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))  # type: ignore\n",
    "\n",
    "    for file in files:\n",
    "        gdf = gpd.read_file(file)  # load the region shape\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        world.plot(ax=ax, color=\"lightgrey\")\n",
    "        gdf.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\")\n",
    "        ax.set_axis_off()\n",
    "        output_path = file.replace(\".geojson\", \".png\")\n",
    "        plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(region_name, data, latitude, longitude, start_date, end_date):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.set_aspect(\"equal\")\n",
    "    # Set vmax to 0.75 for colorbar maximum\n",
    "    plt.pcolormesh(longitude, latitude, data, shading=\"auto\", vmin=0, vmax=0.75)\n",
    "    plt.colorbar(label=\"Chlorophyll-a concentration\", extend=\"max\")\n",
    "    plt.title(f\"Region: {region_name}\\n{start_date} to {end_date}\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.savefig(f\"./plots/{region_name}/{start_date}_{end_date}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_mean(region_name: str, mean_values: dict[str, float]):\n",
    "    # Create a new figure for the time series plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Extract dates and mean values\n",
    "    dates = [\n",
    "        datetime.strptime(date_str[:8], \"%Y%m%d\") for date_str in mean_values.keys()\n",
    "    ]\n",
    "    values = list(mean_values.values())\n",
    "\n",
    "    # Plot the time series\n",
    "    ax.plot_date(dates, values, fmt=\"-\")\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Mean Chlorophyll-a Concentration\")\n",
    "    ax.set_title(\"Chlorophyll-a Concentration Over Time\")\n",
    "\n",
    "    # Rotate x-axis labels for better visibility\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Adjust x-axis tick locator to show dates\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "\n",
    "    plt.savefig(f\"./plots/{region_name}/{region_name}_mean.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(data_series, region_name):\n",
    "    dates = [info[\"start_date\"] for info in data_series]\n",
    "    # Ensure that the data is copied from the original dataset to a writable array\n",
    "    means = [\n",
    "        np.nanmean(np.array(info[\"data\"]))\n",
    "        for info in data_series\n",
    "        if info[\"data\"].size > 0\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(dates, means, marker=\"o\", linestyle=\"-\")\n",
    "    plt.title(f\"Time Series of Mean Chlorophyll-a Concentration for {region_name}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Mean Chlorophyll-a Concentration\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./plots/{region_name}/time_series.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data_series, region_name):\n",
    "    try:\n",
    "        valid_data_series = [\n",
    "            d\n",
    "            for d in data_series\n",
    "            if \"start_date\" in d and \"end_date\" in d and d[\"data\"].size > 0\n",
    "        ]\n",
    "\n",
    "        if not valid_data_series:\n",
    "            print(f\"No valid data to process for {region_name}.\")\n",
    "            return\n",
    "\n",
    "        # Define columns as just the months in a single year\n",
    "        months = [\n",
    "            \"Jan\",\n",
    "            \"Feb\",\n",
    "            \"Mar\",\n",
    "            \"Apr\",\n",
    "            \"May\",\n",
    "            \"Jun\",\n",
    "            \"Jul\",\n",
    "            \"Aug\",\n",
    "            \"Sep\",\n",
    "            \"Oct\",\n",
    "            \"Nov\",\n",
    "            \"Dec\",\n",
    "        ]\n",
    "\n",
    "        # Create an empty DataFrame with years as index and months as columns\n",
    "        years = sorted(set([d[\"start_date\"].year for d in valid_data_series]))\n",
    "        df = pd.DataFrame(index=years, columns=months)\n",
    "\n",
    "        for entry in valid_data_series:\n",
    "            data_copy = np.array(entry[\"data\"]).copy()\n",
    "            mean_value = (\n",
    "                np.nanmean(data_copy) if np.any(~np.isnan(data_copy)) else np.nan\n",
    "            )\n",
    "            month = entry[\"start_date\"].strftime(\"%b\")\n",
    "            year = entry[\"start_date\"].year\n",
    "            # Set the mean value at the correct year and month\n",
    "            df.at[year, month] = mean_value\n",
    "\n",
    "        # Remove any rows that are entirely NaN\n",
    "        df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(f\"./data_csv/{region_name}\", exist_ok=True)\n",
    "\n",
    "        # Save to CSV\n",
    "        csv_path = (\n",
    "            f\"./data_csv/{region_name}/chlorophyll_monthly_means_{region_name}.csv\"\n",
    "        )\n",
    "        df.to_csv(csv_path, index_label=\"year\")\n",
    "        print(f\"CSV file created for {region_name} at {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process data for {region_name}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir_path: str, file_type: str):\n",
    "    # find all the files in a directory\n",
    "    files = [\n",
    "        os.path.join(dir_path, file)\n",
    "        for file in os.listdir(dir_path)\n",
    "        if file.endswith(\".\" + file_type)\n",
    "    ]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7404/4044039121.py:3: FutureWarning: The geopandas.dataset module is deprecated and will be removed in GeoPandas 1.0. You can get the original 'naturalearth_lowres' data from https://www.naturalearthdata.com/downloads/110m-cultural-vectors/.\n",
      "  world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "## import the GeoJSON files which contains the coordinates of the region(s) of interest\n",
    "# find all the geojson files in a directory\n",
    "\n",
    "locs_files = get_files(LOCATIONS_DIR, \"geojson\")\n",
    "geojson_context_figure(locs_files)\n",
    "\n",
    "# read the GeoJSON files\n",
    "gdf_list = [gpd.read_file(file) for file in locs_files]\n",
    "\n",
    "# set the limits of the region(s) of interest with lists for each min and max\n",
    "x_min_list = [gdf.total_bounds[0] for gdf in gdf_list]\n",
    "y_min_list = [gdf.total_bounds[1] for gdf in gdf_list]\n",
    "x_max_list = [gdf.total_bounds[2] for gdf in gdf_list]\n",
    "y_max_list = [gdf.total_bounds[3] for gdf in gdf_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data files available: 11\n"
     ]
    }
   ],
   "source": [
    "data_files = get_files(DATA_DIR, \"nc\")\n",
    "data_files.sort()\n",
    "\n",
    "# parse the start and end date information from the filename (AQUA_MODIS.20210101_20210131.L3m.MO.CHL.chlor_a.4km.nc) of each file and convert it to a datetime object\n",
    "start_date = [\n",
    "    datetime.strptime(file.split(\"/\")[-1].split(\".\")[1].split(\"_\")[0], \"%Y%m%d\")\n",
    "    for file in data_files\n",
    "]\n",
    "end_date = [\n",
    "    datetime.strptime(file.split(\"/\")[-1].split(\".\")[1].split(\"_\")[1], \"%Y%m%d\")\n",
    "    for file in data_files\n",
    "]\n",
    "\n",
    "# create a list of dictionaries containing the filename, start date and end date for each file\n",
    "data_files_info = [\n",
    "    {\"filename\": file, \"start_date\": start, \"end_date\": end}\n",
    "    for file, start, end in zip(data_files, start_date, end_date)\n",
    "]\n",
    "\n",
    "# specify the start and end dates for the desired date range\n",
    "start_date_range = datetime(2021, 1, 1)\n",
    "end_date_range = datetime.now()  # datetime(2022, 12, 31)\n",
    "\n",
    "# print the the number of data files available\n",
    "print(f\"Total data files available: {len(data_files_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected date range: 2021-01-01 00:00:00 to 2024-06-28 12:49:19.587007\n",
      "Total data files available within the date range: 11\n"
     ]
    }
   ],
   "source": [
    "# filter the data_files_info list based on the date range\n",
    "filtered_files_info = [\n",
    "    file_info\n",
    "    for file_info in data_files_info\n",
    "    if start_date_range <= file_info[\"start_date\"] <= end_date_range\n",
    "    and start_date_range <= file_info[\"end_date\"] <= end_date_range\n",
    "]\n",
    "\n",
    "print(f\"Selected date range: {start_date_range} to {end_date_range}\")\n",
    "print(f\"Total data files available within the date range: {len(filtered_files_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading global data:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading global data: 100%|██████████| 11/11 [00:00<00:00, 104.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful loads: 11\n",
      "Unsuccessful loads: 0\n",
      "Size of data loaded: 184 bytes (~0.00 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "successful_loads = 0\n",
    "unsuccessful_loads = 0\n",
    "data_list = []\n",
    "\n",
    "# read the data\n",
    "for file_info in tqdm(filtered_files_info, desc=\"Loading global data\"):\n",
    "    try:\n",
    "        data = nc.Dataset(file_info[\"filename\"], \"r\")  # type: ignore\n",
    "        successful_loads += 1\n",
    "        data_list.append(\n",
    "            {\n",
    "                \"data\": data,\n",
    "                \"start_date\": file_info[\"start_date\"],\n",
    "                \"end_date\": file_info[\"end_date\"],\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        unsuccessful_loads += 1\n",
    "\n",
    "print(f\"Successful loads: {successful_loads}\")\n",
    "print(f\"Unsuccessful loads: {unsuccessful_loads}\")\n",
    "print(\n",
    "    f\"Size of data loaded: {sys.getsizeof(data_list)} bytes (~{(sys.getsizeof(data_list) / 1024**3):.2f} GB)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_data = {\n",
    "    gdf_name: []\n",
    "    for gdf_name in [\n",
    "        os.path.basename(locs_file).replace(\".geojson\", \"\") for locs_file in locs_files\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping data to region of interest:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping data to region of interest: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# loop through all the data, and crop it to the region of interest\n",
    "for data_info in tqdm(data_list, desc=\"Cropping data to region of interest\"):\n",
    "    latitude = data_info[\"data\"][\"lat\"][:]\n",
    "    longitude = data_info[\"data\"][\"lon\"][:]\n",
    "    chlor_a = data_info[\"data\"][\"chlor_a\"][:]\n",
    "    # replace fill values with NaN for better plotting\n",
    "    fill_value = data_info[\"data\"][\"chlor_a\"]._FillValue\n",
    "    chlor_a[chlor_a == fill_value] = np.nan\n",
    "    chlor_a[chlor_a < 0] = np.nan  # set any data below 0 to NaN\n",
    "\n",
    "    # loop through each region\n",
    "    for i, gdf in enumerate(gdf_list):\n",
    "        chlor_a_crop = chlor_a[\n",
    "            (latitude >= y_min_list[i]) & (latitude <= y_max_list[i]), :\n",
    "        ]\n",
    "        chlor_a_crop = chlor_a_crop[\n",
    "            :, (longitude >= x_min_list[i]) & (longitude <= x_max_list[i])\n",
    "        ]\n",
    "        longitude_crop = longitude[\n",
    "            (longitude >= x_min_list[i]) & (longitude <= x_max_list[i])\n",
    "        ]\n",
    "        latitude_crop = latitude[\n",
    "            (latitude >= y_min_list[i]) & (latitude <= y_max_list[i])\n",
    "        ]\n",
    "        region_name = os.path.basename(locs_files[i]).replace(\".geojson\", \"\")\n",
    "        time_series_data[region_name].append(\n",
    "            {\n",
    "                \"data\": chlor_a_crop,\n",
    "                \"latitude\": latitude_crop,\n",
    "                \"longitude\": longitude_crop,\n",
    "                \"start_date\": data_info[\"start_date\"],\n",
    "                \"end_date\": data_info[\"end_date\"],\n",
    "                \"region_name\": region_name,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created for snake at ./data_csv/snake/chlorophyll_monthly_means_snake.csv\n",
      "Data cropped and time series plotted.\n"
     ]
    }
   ],
   "source": [
    "for region_name, data_series in time_series_data.items():\n",
    "\n",
    "    os.makedirs(f\"./plots/{region_name}\", exist_ok=True)\n",
    "    # plot_time_series(data_series, region_name)\n",
    "    write_to_csv(data_series, region_name)\n",
    "\n",
    "del data_list\n",
    "print(\"Data cropped and time series plotted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: snake, time period: 20230201_20230228, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20230301_20230331, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20230401_20230430, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20230501_20230531, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20230601_20230630, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20230701_20230731, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20230801_20230831, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20230901_20230930, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20231001_20231031, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20231101_20231130, NaNs: 0, Total: 257762, % NaNs: 0.00%\n",
      "Region: snake, time period: 20231201_20231231, NaNs: 0, Total: 257762, % NaNs: 0.00%\n"
     ]
    }
   ],
   "source": [
    "for region in time_series_data.keys():\n",
    "    mean_values = {}\n",
    "    for data_info in time_series_data[region]:\n",
    "        time_period = f\"{data_info['start_date'].strftime('%Y%m%d')}_{data_info['end_date'].strftime('%Y%m%d')}\"\n",
    "        # print the number of nans in the data\n",
    "        nans = np.isnan(data_info[\"data\"]).sum()\n",
    "        total = data_info[\"data\"].size\n",
    "        print(\n",
    "            f\"Region: {region}, time period: {time_period}, NaNs: {nans}, Total: {total}, % NaNs: {nans / total * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Calculate mean value\n",
    "        mean_value = np.mean(data_info[\"data\"])\n",
    "\n",
    "        # Store mean value in dictionary\n",
    "        \n",
    "        mean_values[time_period] = mean_value\n",
    "\n",
    "    os.makedirs(f\"./plots/{region}\", exist_ok=True)  \n",
    "    plot_data_mean(f\"{region}\", mean_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
